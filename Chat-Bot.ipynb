{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чат-бот: погода\n",
    "  \n",
    "### Найти бота в Телеграм можно по [ссылке](https://t.me/Garganova_weather_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pymorphy2\n",
    "import collections \n",
    "import multiprocessing\n",
    "\n",
    "import telebot\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш бот будет уметь различать тон сообщения, и реагировать на плохие сообщения и на хорошие по разному. Для этого необходимо провести анализ тональности текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ тональности текста (sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения возьмем [корпус коротких текстов Юлии Рубцовой](http://study.mokoron.com), сформированный на основе русскоязычных сообщений из Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем данные\n",
    "\n",
    "n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faw', 'stcount', 'foll', 'frien', 'listcount']\n",
    "data_positive = pd.read_csv('/Users/elizaveta/Downloads/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "data_negative = pd.read_csv('/Users/elizaveta/Downloads/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "\n",
    "# Формируем сбалансированный датасет\n",
    "\n",
    "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
    "raw_data = np.concatenate((data_positive['text'].values[:sample_size],\n",
    "                           data_negative['text'].values[:sample_size]), axis=0)\n",
    "labels = [1] * sample_size + [0] * sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем ненужные символы\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
    "    text = re.sub('@[^\\s]+', 'USER', text)\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [preprocess_text(t) for t in raw_data]\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нормализуем слова**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция нормализации\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    words = text.split() \n",
    "    res = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Распараллелим (Все равно работает долго!)\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "norm_x_train = pool.map(lemmatize, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Скачиваем стоп-слова, чтобы удалить их из рассмотрения\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем стоп-слова\n",
    "\n",
    "stopwords_set = set(stopwords.words(\"russian\"))\n",
    "# А еще стоит удалить некоторые другие бессмысленные слова, встречающиеся очень часто\n",
    "stopwords_set.add('user')\n",
    "stopwords_set.add('url')\n",
    "stopwords_set.add('rt')\n",
    "stopwords_set.add('весь')\n",
    "stopwords_set.add('это')\n",
    "stopwords_set.add('d')\n",
    "\n",
    "for i in range(len(norm_x_train)):\n",
    "    norm_x_train[i] = list(set(norm_x_train[i]) - stopwords_set)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Векторизация TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединим нормализованные слова обратно в тексты\n",
    "\n",
    "train_texts = []\n",
    "for i in range(len(norm_x_train)):\n",
    "    train_texts.append(' '.join(norm_x_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучаем Логистическую регрессию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logreg_clf = LogisticRegression()\n",
    "logreg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка точности предсказаний**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соединим теперь всю обработку в одну функцию, чтобы также векторизовать тестовую выборку\n",
    "\n",
    "def preproc_x(x_test):\n",
    "    norm_x_test = pool.map(lemmatize, x_test)\n",
    "    for i in range(len(norm_x_test)):\n",
    "        norm_x_test[i] = list(set(norm_x_test[i]) - stopwords_set) \n",
    "    test_texts = []\n",
    "    for i in range(len(norm_x_test)):\n",
    "        test_texts.append(' '.join(norm_x_test[i]))\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания\n",
    "\n",
    "X_test = preproc_x(x_test)\n",
    "y_pred = logreg_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Вычисляем метрики\n",
    "\n",
    "print('Accuracy:',  accuracy_score(y_test, y_pred))       \n",
    "print('Precision:',  precision_score(y_test, y_pred))\n",
    "print('Recall:',  recall_score(y_test, y_pred))\n",
    "print('F1:',  f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Парсим погоду\n",
    "Гисметео и Яндекс.Погода весьма не сговорчивы для парсинга, пришлось довольствоваться Рамблер погодой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msc - Москва, spb - СПб\n",
    "\n",
    "url_msc = 'https://weather.rambler.ru/v-moskve/3-days/'\n",
    "url_spb = 'https://weather.rambler.ru/v-sankt-peterburge/3-days/'\n",
    "\n",
    "html_msc = rq.get(url_msc).text\n",
    "html_spb = rq.get(url_spb).text\n",
    "\n",
    "soup_msc = BeautifulSoup(html_msc,'html.parser')\n",
    "soup_spb = BeautifulSoup(html_spb,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day - число месяца, temp - температура, wind - ветер, wet - вероятность осадков\n",
    "\n",
    "day_msc = [soup_msc.findAll(\"span\", {\"class\":'_30Ou'})[i].text for i in range(3)]\n",
    "temp_msc = [soup_msc.findAll(\"span\", {\"class\":'_3tD7'})[i].text for i in range(3)]\n",
    "wind_msc = [soup_msc.findAll(\"span\", {\"class\":'_3ty-'})[i].text for i in range(3)]\n",
    "wet_msc = [soup_msc.findAll(\"span\", {\"class\":'_3TiQ'})[i].text for i in range(3)]\n",
    "\n",
    "day_spb = [soup_spb.findAll(\"span\", {\"class\":'_30Ou'})[i].text for i in range(3)]\n",
    "temp_spb = [soup_spb.findAll(\"span\", {\"class\":'_3tD7'})[i].text for i in range(3)]\n",
    "wind_spb = [soup_spb.findAll(\"span\", {\"class\":'_3ty-'})[i].text for i in range(3)]\n",
    "wet_spb = [soup_spb.findAll(\"span\", {\"class\":'_3TiQ'})[i].text for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим еще привычные значки с осадками, зависящие от вероятности осадков\n",
    "\n",
    "def wet_pict(wet_list):\n",
    "    pictures = []\n",
    "    integers = []  # это будет список со значениями вероятностей в цифрах (без знака процента)\n",
    "    for i in range(len(wet_list)):\n",
    "        integers.append(int(re.sub('%', '', wet_list[i])))\n",
    "        if integers[-1] == 0:\n",
    "            pictures.append('🌤')  # может быть и солнечно, а могут быть и облака при нулевой вероятности осадков\n",
    "        elif integers[-1] >= 50:\n",
    "            pictures.append('🌧')\n",
    "        else:\n",
    "            pictures.append('☁️')\n",
    "    return pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_pict_msc = wet_pict(wet_msc)\n",
    "wet_pict_spb = wet_pict(wet_spb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_pict_msc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А теперь приступим к созданию самого бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = telebot.TeleBot('1401865395:AAEwGnbN8K69WutpTuorWN-r3R8BtHmxxXo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Кнопки для выбора города\n",
    "\n",
    "cities = telebot.types.InlineKeyboardMarkup()\n",
    "cities.add(telebot.types.InlineKeyboardButton(text=\"Москва\", callback_data=\"msc\"))\n",
    "cities.add(telebot.types.InlineKeyboardButton(text=\"Санкт-Петербург\", callback_data=\"spb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка сообщений\n",
    "\n",
    "@bot.message_handler(content_types=['text'])\n",
    "def get_text_messages(message):\n",
    "    \n",
    "    # Анализ тональности сообщения\n",
    "    mes = logreg_clf.predict(preproc_x([message.text]))[0]\n",
    "    \n",
    "    # Типовые вопросы\n",
    "    t = re.search(r'(проща)|(до свидания)|(до скоро)|(уйти)|(заверш)|(закр)|(выйти)|(отключ)', message.text.lower()) is None\n",
    "    w = re.search(r'(погод)|(спб)|(питер)|(санкт)|(петер)|(мск)|(москв)', message.text.lower()) is None\n",
    "    \n",
    "    # Приветствие\n",
    "    if (message.text == \"/start\") or (message.text.lower() == \"привет\"):\n",
    "        bot.send_message(message.from_user.id,\n",
    "                         \"Привет! Я предсказываю погоду ☀️ Для какого города ты бы хотел ее узнать?\", reply_markup=cities)\n",
    "    # Прощание\n",
    "    elif message.text.lower() == \"пока\":\n",
    "        bot.send_message(message.from_user.id, 'До скорой встречи! 👋🏻')\n",
    "    elif t == False:\n",
    "        bot.send_message(message.from_user.id, 'Хочешь попрощаться? Напиши мне \"Пока\"')\n",
    "    \n",
    "    # Погода в другом городе?\n",
    "    elif w == False:\n",
    "        bot.send_message(message.from_user.id, 'Хочешь теперь узнать погоду в другом городе? Выбирай!', reply_markup=cities)\n",
    "    \n",
    "    # Положительное или отрицательное сообщение?\n",
    "    elif mes == 1:\n",
    "        bot.send_message(message.from_user.id, \"Чувствую, что ты написал мне что-то хорошее, но что - понять не могу 🧐 К сожалению, я умею только предсказывать погоду. Хочешь еще раз скажу? Выбирай город!\", reply_markup=cities)\n",
    "    else:\n",
    "        bot.send_message(message.from_user.id, \"Чувствую, что ты написал мне что-то плохое, но за что? Я ведь просто бот 😔 Если я плохо работаю, можешь пожаловаться моей создательнице: @lizagarganova\")\n",
    "        bot.send_sticker(message.from_user.id, \"CAACAgIAAxkBAAKCb1_YcC8lMuLIC65QXnbkJlvPYCVmAAJiBQACP5XMCkCIeReG4EyMHgQ\")\n",
    "        bot.send_message(message.from_user.id, \"Могу еще чем-то помочь?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ответ на выбор города\n",
    "\n",
    "@bot.callback_query_handler(func=lambda call: True)\n",
    "def callback_worker(call):\n",
    "    if call.data == \"msc\":\n",
    "        msg = 'В Москве ' + day_msc[0] + ' ' + wet_pict_msc[0] + '\\nТемпература воздуха ' + temp_msc[0] + '\\nВетер ' + \\\n",
    "            wind_msc[0] + '\\nВероятность осадков ' + wet_msc[0] + \\\n",
    "            '\\n\\n' + day_msc[1] + ' ' + wet_pict_msc[1] + '\\nТемпература воздуха ' + temp_msc[1] + '\\nВетер ' + \\\n",
    "            wind_msc[1] + '\\nВероятность осадков ' + wet_msc[1] + \\\n",
    "            '\\n\\n' + day_msc[2] + ' ' + wet_pict_msc[2] + '\\nТемпература воздуха ' + temp_msc[2] + '\\nВетер ' + \\\n",
    "            wind_msc[2] + '\\nВероятность осадков ' + wet_msc[2]\n",
    "        bot.send_message(call.message.chat.id, msg)\n",
    "        bot.send_message(call.message.chat.id, 'Могу ли быть полезен чем-то еще?')\n",
    "    elif call.data == \"spb\":\n",
    "        msg = 'В Санкт-Петербурге ' + day_spb[0] + ' ' + wet_pict_spb[0] + '\\nТемпература воздуха ' + temp_spb[0] + '\\nВетер ' + \\\n",
    "            wind_spb[0] + '\\nВероятность осадков ' + wet_spb[0] + \\\n",
    "            '\\n\\n' + day_spb[1] + ' ' + wet_pict_spb[1] + '\\nТемпература воздуха ' + temp_spb[1] + '\\nВетер ' + \\\n",
    "            wind_spb[1] + '\\nВероятность осадков ' + wet_spb[1] + \\\n",
    "            '\\n\\n' + day_spb[2] + ' ' + wet_pict_spb[2] + '\\nТемпература воздуха ' + temp_spb[2] + '\\nВетер ' + \\\n",
    "            wind_spb[2] + '\\nВероятность осадков ' + wet_spb[2] \n",
    "        bot.send_message(call.message.chat.id, msg)\n",
    "        bot.send_message(call.message.chat.id, 'Могу ли быть полезен чем-то еще?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запускаем нашего бота\n",
    "\n",
    "bot.polling(none_stop=True, interval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
